{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sCV30xyVhFbE"},"outputs":[],"source":["#Convolutional Neural Network\n","#Importing the libraries\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIleuCAjoFD8","outputId":"6e7ef67b-0dda-40f0-835c-6896d489f1e6"},"outputs":[{"data":{"text/plain":["'2.9.1'"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["tf.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0koUcJMJpEBD","outputId":"844b5076-3f28-4a20-c0c8-a1f24fb9e69e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 8000 images belonging to 2 classes.\n"]}],"source":["#Data Preprocessing\n","#Preprocessing the Training set\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","training_set = train_datagen.flow_from_directory('d:/training_set',\n","                                                 target_size = (64, 64),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'binary')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SH4WzfOhpKc3","outputId":"99c6a09f-58e0-4a2c-9caa-1ef2682c59be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n"]}],"source":["#Preprocessing the Test set\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory('d:/test_set',\n","                                            target_size = (64, 64),\n","                                            batch_size = 32,\n","                                            class_mode = 'binary')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SAUt4UMPlhLS"},"outputs":[],"source":["#Building the CNN\n","#Initialisig the CNN\n","cnn = tf.keras.models.Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPzPrMckl-hV"},"outputs":[],"source":["#Step1- Convolution\n","cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncpqPl69mOac"},"outputs":[],"source":["#Step3-pooling\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i_-FZjn_m8gk"},"outputs":[],"source":["#Adding a second Convolutional layer\n","cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6AZeOGCvnNZn"},"outputs":[],"source":["#Flattening\n","cnn.add(tf.keras.layers.Flatten())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GtmUlLd26Nq"},"outputs":[],"source":["#Step4 - Full connection\n","cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1p_Zj1Mc3Ko_"},"outputs":[],"source":["#Output Layers\n","cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NALksrNQpUlJ"},"outputs":[],"source":["#Traininig the CNN\n","#Compiling the CNN\n","cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XUj1W4PJptta","outputId":"426455c3-3463-40bb-ef22-4f978c71d710"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","250/250 [==============================] - 181s 720ms/step - loss: 0.6567 - accuracy: 0.6083 - val_loss: 0.6039 - val_accuracy: 0.6635\n","Epoch 2/25\n","250/250 [==============================] - 34s 134ms/step - loss: 0.5942 - accuracy: 0.6798 - val_loss: 0.6085 - val_accuracy: 0.6555\n","Epoch 3/25\n","250/250 [==============================] - 33s 130ms/step - loss: 0.5573 - accuracy: 0.7066 - val_loss: 0.5425 - val_accuracy: 0.7305\n","Epoch 4/25\n","250/250 [==============================] - 33s 134ms/step - loss: 0.5219 - accuracy: 0.7398 - val_loss: 0.6202 - val_accuracy: 0.6895\n","Epoch 5/25\n","250/250 [==============================] - 27s 107ms/step - loss: 0.4990 - accuracy: 0.7566 - val_loss: 0.4990 - val_accuracy: 0.7605\n","Epoch 6/25\n","250/250 [==============================] - 24s 94ms/step - loss: 0.4865 - accuracy: 0.7657 - val_loss: 0.4898 - val_accuracy: 0.7745\n","Epoch 7/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.4736 - accuracy: 0.7663 - val_loss: 0.4773 - val_accuracy: 0.7730\n","Epoch 8/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.4459 - accuracy: 0.7879 - val_loss: 0.4991 - val_accuracy: 0.7620\n","Epoch 9/25\n","250/250 [==============================] - 23s 94ms/step - loss: 0.4365 - accuracy: 0.8005 - val_loss: 0.5171 - val_accuracy: 0.7540\n","Epoch 10/25\n","250/250 [==============================] - 23s 94ms/step - loss: 0.4206 - accuracy: 0.8019 - val_loss: 0.4763 - val_accuracy: 0.7780\n","Epoch 11/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.4179 - accuracy: 0.8084 - val_loss: 0.4638 - val_accuracy: 0.7915\n","Epoch 12/25\n","250/250 [==============================] - 24s 96ms/step - loss: 0.4048 - accuracy: 0.8149 - val_loss: 0.5032 - val_accuracy: 0.7690\n","Epoch 13/25\n","250/250 [==============================] - 23s 93ms/step - loss: 0.4006 - accuracy: 0.8106 - val_loss: 0.5223 - val_accuracy: 0.7645\n","Epoch 14/25\n","250/250 [==============================] - 24s 94ms/step - loss: 0.3815 - accuracy: 0.8245 - val_loss: 0.4447 - val_accuracy: 0.8015\n","Epoch 15/25\n","250/250 [==============================] - 34s 135ms/step - loss: 0.3675 - accuracy: 0.8381 - val_loss: 0.4538 - val_accuracy: 0.7960\n","Epoch 16/25\n","250/250 [==============================] - 57s 227ms/step - loss: 0.3543 - accuracy: 0.8459 - val_loss: 0.4843 - val_accuracy: 0.7865\n","Epoch 17/25\n","250/250 [==============================] - 36s 145ms/step - loss: 0.3396 - accuracy: 0.8500 - val_loss: 0.4645 - val_accuracy: 0.7960\n","Epoch 18/25\n","250/250 [==============================] - 34s 137ms/step - loss: 0.3332 - accuracy: 0.8539 - val_loss: 0.4572 - val_accuracy: 0.7995\n","Epoch 19/25\n","250/250 [==============================] - 35s 139ms/step - loss: 0.3174 - accuracy: 0.8575 - val_loss: 0.4783 - val_accuracy: 0.8035\n","Epoch 20/25\n","250/250 [==============================] - 34s 135ms/step - loss: 0.3016 - accuracy: 0.8708 - val_loss: 0.4646 - val_accuracy: 0.8005\n","Epoch 21/25\n","250/250 [==============================] - 34s 134ms/step - loss: 0.2975 - accuracy: 0.8691 - val_loss: 0.5063 - val_accuracy: 0.8005\n","Epoch 22/25\n","250/250 [==============================] - 34s 136ms/step - loss: 0.2846 - accuracy: 0.8766 - val_loss: 0.5023 - val_accuracy: 0.8010\n","Epoch 23/25\n","250/250 [==============================] - 33s 133ms/step - loss: 0.2681 - accuracy: 0.8885 - val_loss: 0.5331 - val_accuracy: 0.7935\n","Epoch 24/25\n","250/250 [==============================] - 32s 128ms/step - loss: 0.2623 - accuracy: 0.8913 - val_loss: 0.5438 - val_accuracy: 0.7935\n","Epoch 25/25\n","250/250 [==============================] - 33s 133ms/step - loss: 0.2450 - accuracy: 0.8959 - val_loss: 0.5559 - val_accuracy: 0.7870\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x263d0fe50a0>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["#Training the CNN on the Training set and evaluating it on the Test set\n","cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsSiWEJY1BPB","outputId":"76b9318f-d968-445d-c012-0087dea371e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 24ms/step\n"]}],"source":["#Making a single predition\n","import numpy as np\n","from keras.preprocessing import image\n","import keras.utils as image\n","test_image = image.load_img('D:/composite analytics statstics and ML_Deloitte/dataset/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1:\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ED9KB3I54c1i","outputId":"9515f250-ea09-4c68-cbc2-299018a269f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["cat\n"]}],"source":["print(prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMlO_ewFtrtl"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"viADjtjrtrtl"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}