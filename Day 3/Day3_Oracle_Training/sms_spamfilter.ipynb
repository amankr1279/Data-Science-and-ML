{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca22b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sms_spam = pd.read_csv('/Users/amankumar/Desktop/Work/Trainings/Data Science and ML/Day 3/sms_spam.csv')\n",
    "\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51b7d08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "ham     0.865985\n",
       "spam    0.134015\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d72e10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the dataset\n",
    "data_randomized = sms_spam.sample(frac=1, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "674c55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "332980a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6809ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4459, 2)\n",
      "(1115, 2)\n"
     ]
    }
   ],
   "source": [
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b25559b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "ham     0.865216\n",
       "spam    0.134784\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aa1139a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "ham     0.869058\n",
       "spam    0.130942\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2c098b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Looks like u wil b getting a headstart im leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>I noe la... U wana pei bf oso rite... K lor, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>2mro i am not coming to gym machan. Goodnight.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type                                               text\n",
       "0  ham  Looks like u wil b getting a headstart im leav...\n",
       "1  ham  I noe la... U wana pei bf oso rite... K lor, o...\n",
       "2  ham     2mro i am not coming to gym machan. Goodnight."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before cleaning\n",
    "training_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e70f38c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>looks like u wil b getting a headstart im leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>i noe la    u wana pei bf oso rite    k lor  o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>2mro i am not coming to gym machan  goodnight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type                                               text\n",
       "0  ham  looks like u wil b getting a headstart im leav...\n",
       "1  ham  i noe la    u wana pei bf oso rite    k lor  o...\n",
       "2  ham     2mro i am not coming to gym machan  goodnight "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Data clensing\n",
    "training_set['text'] = training_set['text'].str.replace(r'\\W', ' ', regex=True) # Removes punctuation\n",
    "training_set['text'] = training_set['text'].str.lower()\n",
    "training_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c85920ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncreate the vocabulary\\nWe transform each message in thetext column into a list by splitting the string at the space character — we're using the Series.str.split() method.\\nWe initiate an empty list named vocabulary.\\nWe iterate over the transformed text column.\\nUsing a nested loop, we iterate over each message in the text column and append each string (word) to the vocabulary list.\\nWe transform the vocabulary list into a set using the set() function. This will remove the duplicates from the vocabulary list.\\nWe transform the vocabulary set back into a list using the list() function.\\n\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "create the vocabulary\n",
    "We transform each message in thetext column into a list by splitting the string at the space character — we're using the Series.str.split() method.\n",
    "We initiate an empty list named vocabulary.\n",
    "We iterate over the transformed text column.\n",
    "Using a nested loop, we iterate over each message in the text column and append each string (word) to the vocabulary list.\n",
    "We transform the vocabulary list into a set using the set() function. This will remove the duplicates from the vocabulary list.\n",
    "We transform the vocabulary set back into a list using the list() function.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "13dda267",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_set['text'] = training_set['text'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for text in training_set['text']:\n",
    "   for word in text:\n",
    "      vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e09a74f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7802"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d959e510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['88800',\n",
       " 'drug',\n",
       " 'beendropping',\n",
       " 'epsilon',\n",
       " 'rings',\n",
       " 'mids',\n",
       " 'downon',\n",
       " 'greatness',\n",
       " 'pieces',\n",
       " '3230',\n",
       " 'theatre',\n",
       " 'least',\n",
       " 'loooooool',\n",
       " 'lovers',\n",
       " '169',\n",
       " 'aft',\n",
       " 'suffers',\n",
       " 'grooved',\n",
       " 'webeburnin',\n",
       " 'sao',\n",
       " 'bambling',\n",
       " 'lar',\n",
       " 'nearby',\n",
       " 'path',\n",
       " 'boundaries',\n",
       " 'effects',\n",
       " 'weird',\n",
       " '400thousad',\n",
       " 'didntgive',\n",
       " 'chocolate',\n",
       " 'apart',\n",
       " 'youi',\n",
       " '4info',\n",
       " 'gumby',\n",
       " 'swalpa',\n",
       " 'shindig',\n",
       " 'havbeen',\n",
       " 'ma',\n",
       " 'writhing',\n",
       " 'figure',\n",
       " 'escape',\n",
       " 'antha',\n",
       " 'os',\n",
       " 'salt',\n",
       " 'aretaking',\n",
       " 'movietrivia',\n",
       " 'position',\n",
       " 'cuck',\n",
       " 'adore',\n",
       " 'teletext',\n",
       " 'meg',\n",
       " 'hugging',\n",
       " 'plans',\n",
       " 'care',\n",
       " 'usher',\n",
       " 'dark',\n",
       " 'raise',\n",
       " 'tape',\n",
       " 'prakasam',\n",
       " 'orh',\n",
       " 'fones',\n",
       " 'sorts',\n",
       " 'goigng',\n",
       " 'term',\n",
       " 'lucky',\n",
       " 'foreign',\n",
       " 'speling',\n",
       " 'yeah',\n",
       " '3aj',\n",
       " '1405',\n",
       " 'contents',\n",
       " '2000',\n",
       " 'obese',\n",
       " 'forward',\n",
       " 'ali',\n",
       " 'grand',\n",
       " 'abta',\n",
       " 'station',\n",
       " 'walkin',\n",
       " 'persevered',\n",
       " 'painting',\n",
       " 'retard',\n",
       " 'ugh',\n",
       " 'un',\n",
       " 'fifth',\n",
       " 'after',\n",
       " 'cards',\n",
       " 'cleared',\n",
       " 'bin',\n",
       " 'units',\n",
       " 'mornin',\n",
       " 'headin',\n",
       " 'go2',\n",
       " 'overa',\n",
       " 'huh',\n",
       " 'tcr',\n",
       " 'casualty',\n",
       " 'com1win150ppmx3age16',\n",
       " 'tor',\n",
       " 'balls',\n",
       " 'urgnt',\n",
       " 'renewing',\n",
       " 'enters',\n",
       " 'tampa',\n",
       " 'supposed',\n",
       " 'terrible',\n",
       " 'quickly',\n",
       " '08452810073',\n",
       " '09066350750',\n",
       " 'scorable',\n",
       " 'buz',\n",
       " 'kind',\n",
       " 'tke',\n",
       " 'hv9d',\n",
       " 'aberdeen',\n",
       " 'housewives',\n",
       " 'yah',\n",
       " 'temple',\n",
       " 'nino',\n",
       " 'gentleman',\n",
       " '08704050406',\n",
       " 'plaza',\n",
       " 'remembr',\n",
       " 'jacket',\n",
       " 'hadn',\n",
       " 'http',\n",
       " 'mall',\n",
       " 'lambda',\n",
       " 'fathima',\n",
       " 'naughty',\n",
       " '07008009200',\n",
       " 'vaazhthukkal',\n",
       " 'pongal',\n",
       " 'prasanth',\n",
       " 'lapdancer',\n",
       " '523',\n",
       " 'compliments',\n",
       " 'purple',\n",
       " 'step',\n",
       " 'smells',\n",
       " 'daaaaa',\n",
       " '80878',\n",
       " 'public',\n",
       " 'tcs',\n",
       " 'closed',\n",
       " 'box245c2150pm',\n",
       " 'control',\n",
       " 'managed',\n",
       " 'process',\n",
       " 'prevent',\n",
       " 'mite',\n",
       " 'computational',\n",
       " 'tok',\n",
       " 'necesity',\n",
       " 'ystrday',\n",
       " 'phrase',\n",
       " 'gage',\n",
       " 'great',\n",
       " 'ujhhhhhhh',\n",
       " 'listened2the',\n",
       " 'wkg',\n",
       " 'jas',\n",
       " 'wonders',\n",
       " 'tt',\n",
       " 'mallika',\n",
       " 'b4190604',\n",
       " 'apartment',\n",
       " 'andrews',\n",
       " 'callertune',\n",
       " 'weighed',\n",
       " 'enna',\n",
       " 'opened',\n",
       " 'buses',\n",
       " '08000839402',\n",
       " 'unfolds',\n",
       " 'figures',\n",
       " 'take',\n",
       " 'slowly',\n",
       " '0870737910216yrs',\n",
       " 'cried',\n",
       " 'hex',\n",
       " 'enjoyin',\n",
       " 'bleh',\n",
       " 'tenants',\n",
       " 'maat',\n",
       " 'mathematics',\n",
       " 'je',\n",
       " 'sophas',\n",
       " '447801259231',\n",
       " '45pm',\n",
       " 'toking',\n",
       " 'dey',\n",
       " 'developed',\n",
       " 'nb',\n",
       " 'we',\n",
       " 'initiate',\n",
       " 'wylie',\n",
       " '89080',\n",
       " 'employee',\n",
       " 'borin',\n",
       " 'ukp',\n",
       " 'treated',\n",
       " 'maneesha',\n",
       " 'perumbavoor',\n",
       " '177',\n",
       " '1120',\n",
       " '6',\n",
       " 'hai',\n",
       " 'steve',\n",
       " '08448350055',\n",
       " 'asssssholeeee',\n",
       " 'bpo',\n",
       " '07815296484',\n",
       " 'contacted',\n",
       " 'dumb',\n",
       " 'show',\n",
       " 'rate',\n",
       " 'tolerat',\n",
       " 'recession',\n",
       " 'swhrt',\n",
       " '100',\n",
       " 'annoying',\n",
       " 'teaches',\n",
       " 'ipads',\n",
       " 'wasted',\n",
       " 'event',\n",
       " 'double',\n",
       " 'responsibility',\n",
       " 'lines',\n",
       " 'approve',\n",
       " 'ink',\n",
       " '84025',\n",
       " 'ntt',\n",
       " 'gd',\n",
       " 'motivate',\n",
       " 'scool',\n",
       " '83021',\n",
       " 'thesmszone',\n",
       " '850',\n",
       " 'texting',\n",
       " 'nri',\n",
       " 'xxuk',\n",
       " 'malarky',\n",
       " 'art',\n",
       " 'snickering',\n",
       " 'tihs',\n",
       " '07099833605',\n",
       " 'nature',\n",
       " 'restock',\n",
       " 'loosu',\n",
       " 'cashbin',\n",
       " 'avo',\n",
       " 'wiv',\n",
       " 'prove',\n",
       " 'knackered',\n",
       " 'restaurant',\n",
       " 'astrology',\n",
       " 'impressively',\n",
       " 'greeting',\n",
       " 'oja',\n",
       " 'dept',\n",
       " 'rajitha',\n",
       " 'inspection',\n",
       " 'ts',\n",
       " '10k',\n",
       " 'name1',\n",
       " 'aeronautics',\n",
       " 'simple',\n",
       " 'weaseling',\n",
       " 'calicut',\n",
       " 'starving',\n",
       " 'hasn',\n",
       " 'screen',\n",
       " 'atleast',\n",
       " 'reserved',\n",
       " 'auction',\n",
       " '08448714184',\n",
       " '08714712412',\n",
       " 'carefully',\n",
       " 'chosen',\n",
       " 'smsco',\n",
       " 'fills',\n",
       " 'musical',\n",
       " 'wondering',\n",
       " '08712300220',\n",
       " 'la3',\n",
       " 'infections',\n",
       " 'pobox114',\n",
       " 'officially',\n",
       " 'chill',\n",
       " 'va',\n",
       " '09050001808',\n",
       " 'describe',\n",
       " 'pierre',\n",
       " 'sweets',\n",
       " 'cnl',\n",
       " 'weirdest',\n",
       " 'sweetie',\n",
       " 'cysts',\n",
       " 'dudette',\n",
       " 'oranges',\n",
       " 'soooo',\n",
       " 'movie',\n",
       " 'telling',\n",
       " 'amplikater',\n",
       " 'urgh',\n",
       " 'relocate',\n",
       " 'thousands',\n",
       " 'hun',\n",
       " 'linear',\n",
       " 'parantella',\n",
       " '10p',\n",
       " 'abuse',\n",
       " 'adult',\n",
       " 'mmmm',\n",
       " 'vijay',\n",
       " 'dippeditinadew',\n",
       " 'eldest',\n",
       " '114',\n",
       " 'mush',\n",
       " 'lessons',\n",
       " 'triumphed',\n",
       " 'suggestion',\n",
       " '89545',\n",
       " 'gone',\n",
       " 'community',\n",
       " 'lou',\n",
       " 'sptv',\n",
       " '6ish',\n",
       " 'savamob',\n",
       " '12hours',\n",
       " '86688',\n",
       " 'skip',\n",
       " '08708800282',\n",
       " 'satanic',\n",
       " '69696',\n",
       " 'logoff',\n",
       " 'cock',\n",
       " 'most',\n",
       " 'cheaper',\n",
       " 'yeovil',\n",
       " 'pocay',\n",
       " '600',\n",
       " 'virgins',\n",
       " 'money',\n",
       " '0871',\n",
       " 'doin',\n",
       " 'won',\n",
       " 'chest',\n",
       " 'hand',\n",
       " 'portege',\n",
       " 'patent',\n",
       " 'enufcredeit',\n",
       " '08717895698',\n",
       " '08081263000',\n",
       " 'lifpartnr',\n",
       " 'hairdressers',\n",
       " 'gang',\n",
       " 'flash',\n",
       " '07090298926',\n",
       " 'coins',\n",
       " 'mummy',\n",
       " 'occupied',\n",
       " 'bcaz',\n",
       " 'mfl',\n",
       " 'la',\n",
       " 'elliot',\n",
       " 'showers',\n",
       " 'bong',\n",
       " 'smarter',\n",
       " 'chgs',\n",
       " 'learn',\n",
       " 'totes',\n",
       " 'tolerance',\n",
       " 'singing',\n",
       " 'printed',\n",
       " 'hearing',\n",
       " 'lane',\n",
       " 'thurs',\n",
       " 'pussy',\n",
       " 'left',\n",
       " 'subject',\n",
       " 'idew',\n",
       " 'lst',\n",
       " 'she',\n",
       " 'hurry',\n",
       " 'slots',\n",
       " 'remind',\n",
       " '872',\n",
       " '32000',\n",
       " 'renewed',\n",
       " '8lb',\n",
       " 'sugababes',\n",
       " 'yun',\n",
       " '08712317606',\n",
       " 'beauty',\n",
       " 'manchester',\n",
       " 'ummma',\n",
       " 'helen',\n",
       " 'breather',\n",
       " 'bettersn',\n",
       " '09061221061',\n",
       " 'twittering',\n",
       " '08718723815',\n",
       " 'w111wx',\n",
       " 'o2fwd',\n",
       " 'library',\n",
       " 'bleak',\n",
       " 'ow',\n",
       " 'soon',\n",
       " 'sculpture',\n",
       " 'hows',\n",
       " 'raji',\n",
       " 'aiyo',\n",
       " 'roller',\n",
       " 'lekdog',\n",
       " '3750',\n",
       " 'weapon',\n",
       " 'jolly',\n",
       " '945',\n",
       " 'amnow',\n",
       " 'iriver',\n",
       " 'chic',\n",
       " 'smoking',\n",
       " 'congratulations',\n",
       " 'yan',\n",
       " 'fudge',\n",
       " 'hello',\n",
       " 'hopeso',\n",
       " '2morow',\n",
       " 'bend',\n",
       " 'main',\n",
       " '08718727870',\n",
       " 'tiwary',\n",
       " '09071512433',\n",
       " 'kaila',\n",
       " 'neighbour',\n",
       " 'intend',\n",
       " 'drastic',\n",
       " 'eh',\n",
       " 'reckon',\n",
       " 'saying',\n",
       " 'sudn',\n",
       " 'chinky',\n",
       " '80122300p',\n",
       " 'havent',\n",
       " '0825',\n",
       " 'everythin',\n",
       " 'wasn',\n",
       " 'ag',\n",
       " 'supervisor',\n",
       " 'simpler',\n",
       " '09071517866',\n",
       " 'put',\n",
       " 'man',\n",
       " 'bath',\n",
       " 'guitar',\n",
       " 'tsunamis',\n",
       " 'benefits',\n",
       " 'rencontre',\n",
       " 'semi',\n",
       " 'doll',\n",
       " 'held',\n",
       " '02085076972',\n",
       " 'groovy',\n",
       " 'afraid',\n",
       " 'lk',\n",
       " 'browse',\n",
       " 'dl',\n",
       " 'shexy',\n",
       " 'affair',\n",
       " 'confirm',\n",
       " 'rose',\n",
       " 'burger',\n",
       " 'being',\n",
       " 'ay',\n",
       " 'askd',\n",
       " 'masters',\n",
       " 'albi',\n",
       " 'clearly',\n",
       " '09063442151',\n",
       " 'k52',\n",
       " 'm6',\n",
       " 'erotic',\n",
       " 'shah',\n",
       " 'japanese',\n",
       " 'steak',\n",
       " 'mandan',\n",
       " 'usps',\n",
       " 'weddin',\n",
       " 'beer',\n",
       " 'stories',\n",
       " 'sometime',\n",
       " 'works',\n",
       " 'complementary',\n",
       " 'othrwise',\n",
       " 'gr8prizes',\n",
       " 'future',\n",
       " 'wondarfull',\n",
       " 'noisy',\n",
       " 'fne',\n",
       " 'n',\n",
       " '49557',\n",
       " 'smell',\n",
       " 'ripped',\n",
       " '526',\n",
       " 'goin2bed',\n",
       " 'qatar',\n",
       " 'dine',\n",
       " 'anyone',\n",
       " 'impossible',\n",
       " '786',\n",
       " 'entropication',\n",
       " 'speechless',\n",
       " 'african',\n",
       " 'kills',\n",
       " 'hardly',\n",
       " '7oz',\n",
       " 'worlds',\n",
       " 'piece',\n",
       " 'uncut',\n",
       " 'aburo',\n",
       " 'meive',\n",
       " 'kip',\n",
       " '8th',\n",
       " 'normally',\n",
       " 'delhi',\n",
       " '87239',\n",
       " 'adventure',\n",
       " 'tight',\n",
       " 'fifa',\n",
       " 'hmm',\n",
       " 'blanked',\n",
       " 'trying',\n",
       " 'england',\n",
       " 'infront',\n",
       " '09056242159',\n",
       " '08006344447',\n",
       " 'occasion',\n",
       " 'n8',\n",
       " 'timin',\n",
       " 'phd',\n",
       " 'ileave',\n",
       " 'im',\n",
       " '100percent',\n",
       " 'mustprovide',\n",
       " 'shower',\n",
       " 'faggot',\n",
       " 'sway',\n",
       " 'accordin',\n",
       " 'til',\n",
       " 'checkmate',\n",
       " '8027',\n",
       " 'stash',\n",
       " 'prolly',\n",
       " 'afford',\n",
       " 'usb',\n",
       " 'foot',\n",
       " 'vivekanand',\n",
       " 'luckily',\n",
       " 'v',\n",
       " '83049',\n",
       " 'swtheart',\n",
       " 'certainly',\n",
       " 'dramatic',\n",
       " 'mns',\n",
       " 'unredeemed',\n",
       " 'important',\n",
       " 'elvis',\n",
       " 'bristol',\n",
       " 'follow',\n",
       " 'w1j',\n",
       " 'politicians',\n",
       " 'definitely',\n",
       " 'trusting',\n",
       " 'chillaxin',\n",
       " 'monkeyaround',\n",
       " 'few',\n",
       " 'street',\n",
       " 'report',\n",
       " 'nitros',\n",
       " 'remembered',\n",
       " 'okie',\n",
       " 'person2die',\n",
       " 'nasty',\n",
       " 'spending',\n",
       " 'cali',\n",
       " 'thought',\n",
       " 'whos',\n",
       " '195',\n",
       " 'pictures',\n",
       " 'tel',\n",
       " '15541',\n",
       " 'thuglyfe',\n",
       " 'software',\n",
       " 'easily',\n",
       " 'theater',\n",
       " 'xxxxxxxx',\n",
       " 'onbus',\n",
       " 'ear',\n",
       " '09066358152',\n",
       " 'broken',\n",
       " '8am',\n",
       " 'leh',\n",
       " 'laugh',\n",
       " 'practical',\n",
       " 'advise',\n",
       " 'disconnected',\n",
       " 'simulate',\n",
       " 'bcm1896wc1n3xx',\n",
       " 'oredi',\n",
       " 'noooooooo',\n",
       " 'birds',\n",
       " 'gauti',\n",
       " 'multimedia',\n",
       " 'xin',\n",
       " 'shaping',\n",
       " 'usmle',\n",
       " 'easiest',\n",
       " 'gossip',\n",
       " 'probs',\n",
       " 'ore',\n",
       " 'point',\n",
       " 'devouring',\n",
       " 'gt',\n",
       " 'wedding',\n",
       " 'cust',\n",
       " 'cappuccino',\n",
       " 'vegas',\n",
       " 'marry',\n",
       " 'thus',\n",
       " 'marine',\n",
       " 'remember',\n",
       " 'lifted',\n",
       " 'ask',\n",
       " 'dime',\n",
       " 'payoh',\n",
       " 'squeeeeeze',\n",
       " 'raining',\n",
       " 'virgin',\n",
       " 'applausestore',\n",
       " '69888',\n",
       " 'jesus',\n",
       " 'mid',\n",
       " 'gift',\n",
       " 'success',\n",
       " 'steal',\n",
       " 'callin',\n",
       " 'arrive',\n",
       " 'lord',\n",
       " 'falls',\n",
       " 'enc',\n",
       " 'sexual',\n",
       " 'ki',\n",
       " 'link',\n",
       " 'tuition',\n",
       " 'nalli',\n",
       " 'countin',\n",
       " 'poboxox36504w45wq',\n",
       " '08717205546',\n",
       " 'celebrated',\n",
       " 'supports',\n",
       " 'hypotheticalhuagauahahuagahyuhagga',\n",
       " 'oblisingately',\n",
       " 'polyphonic',\n",
       " 'close',\n",
       " 'porn',\n",
       " 'white',\n",
       " 'club4',\n",
       " 'how',\n",
       " 'cougar',\n",
       " 'cough',\n",
       " 'coz',\n",
       " 'fren',\n",
       " 'wizzle',\n",
       " 'acl03530150pm',\n",
       " 'spain',\n",
       " '2geva',\n",
       " 'wkent',\n",
       " 'buzzzz',\n",
       " '04',\n",
       " 'handsome',\n",
       " 'landlineonly',\n",
       " 'mins',\n",
       " '80082',\n",
       " 'space',\n",
       " 'gifted',\n",
       " 'tata',\n",
       " 'series',\n",
       " 'computerless',\n",
       " 'mobiles',\n",
       " 'starwars3',\n",
       " 'onwards',\n",
       " 'fuck',\n",
       " 'lingerie',\n",
       " 'possessiveness',\n",
       " 'rang',\n",
       " '07753741225',\n",
       " 'usc',\n",
       " '09050003091',\n",
       " 'british',\n",
       " 'busy',\n",
       " 'pressure',\n",
       " 'five',\n",
       " 'thriller',\n",
       " 'ffffffffff',\n",
       " 'assume',\n",
       " 'x49',\n",
       " 'mornings',\n",
       " 'invitation',\n",
       " 'pure',\n",
       " 'jiu',\n",
       " 'study',\n",
       " 'ish',\n",
       " 'attributed',\n",
       " 'monkeys',\n",
       " 'brings',\n",
       " 'audrey',\n",
       " 'sumthin',\n",
       " 'male',\n",
       " 'quoting',\n",
       " 'elections',\n",
       " 'particularly',\n",
       " 'kallis',\n",
       " 'recent',\n",
       " 'request',\n",
       " 'ashes',\n",
       " 'buns',\n",
       " 'professors',\n",
       " '7548',\n",
       " 'bare',\n",
       " 'celebration',\n",
       " 'ridden',\n",
       " 'when',\n",
       " 'mth',\n",
       " 'membership',\n",
       " 'filthy',\n",
       " 'wining',\n",
       " 'virgil',\n",
       " 'jen',\n",
       " 'percent',\n",
       " 'cosign',\n",
       " 'intention',\n",
       " 'nope',\n",
       " 'specs',\n",
       " '79',\n",
       " 'batt',\n",
       " 'duvet',\n",
       " 'acid',\n",
       " 'beeen',\n",
       " 'peril',\n",
       " 'hubby',\n",
       " 'buttons',\n",
       " 'asusual',\n",
       " 'interview',\n",
       " 'rewarding',\n",
       " 'user',\n",
       " 'wifi',\n",
       " 'cruisin',\n",
       " 'tomo',\n",
       " 'j5q',\n",
       " 'film',\n",
       " 'avoiding',\n",
       " 'decide',\n",
       " 'sitter',\n",
       " 'lt',\n",
       " 'fake',\n",
       " 'professional',\n",
       " 'rental',\n",
       " 'mis',\n",
       " 'timi',\n",
       " 'burns',\n",
       " 'appreciate',\n",
       " 'sitting',\n",
       " 'vs',\n",
       " 'shampain',\n",
       " 'wasnt',\n",
       " 'darkness',\n",
       " 'ultimately',\n",
       " '0721072',\n",
       " 'diwali',\n",
       " 'intrepid',\n",
       " 's3xy',\n",
       " '542',\n",
       " 'nigpun',\n",
       " 'unrecognized',\n",
       " '08000776320',\n",
       " 'entey',\n",
       " 'recpt',\n",
       " 'questioned',\n",
       " 'waheed',\n",
       " 'giggle',\n",
       " 'relieved',\n",
       " 'mobsi',\n",
       " 'be',\n",
       " 'website',\n",
       " 'loss',\n",
       " 'ko',\n",
       " 'ger',\n",
       " 'itwhichturnedinto',\n",
       " 'outsider',\n",
       " 'ten',\n",
       " 'dare',\n",
       " 'happenin',\n",
       " 'resent',\n",
       " '1pm',\n",
       " 'tbs',\n",
       " 'exterminator',\n",
       " 'fan',\n",
       " 'drove',\n",
       " 'count',\n",
       " 'computers',\n",
       " 'invoices',\n",
       " 'clean',\n",
       " 'hole',\n",
       " 'argue',\n",
       " 'carpark',\n",
       " 'kiss',\n",
       " 'dick',\n",
       " 'hav',\n",
       " 'regalportfolio',\n",
       " 'muht',\n",
       " 'aphex',\n",
       " '65',\n",
       " 'absolutly',\n",
       " 'kiefer',\n",
       " 'paracetamol',\n",
       " 'foregate',\n",
       " 'indyarocks',\n",
       " 'needs',\n",
       " 'iyo',\n",
       " 'arab',\n",
       " 'bored',\n",
       " 'dracula',\n",
       " 'fly',\n",
       " 'kodstini',\n",
       " 'photos',\n",
       " 'joking',\n",
       " 'badrith',\n",
       " 'satsgettin',\n",
       " 'unlike',\n",
       " 'ed',\n",
       " 'thank',\n",
       " 'payee',\n",
       " 'reboot',\n",
       " 'titles',\n",
       " 'promoting',\n",
       " 'around',\n",
       " 'barred',\n",
       " 'young',\n",
       " 'cookies',\n",
       " 'remains',\n",
       " 'beloved',\n",
       " 'tones2you',\n",
       " 'always',\n",
       " 'bmw',\n",
       " 'smacks',\n",
       " 'neft',\n",
       " 'wild',\n",
       " 'leanne',\n",
       " 'mrng',\n",
       " 'superb',\n",
       " 'buzz',\n",
       " 'categories',\n",
       " 'angels',\n",
       " 'idps',\n",
       " 'shade',\n",
       " 'complimentary',\n",
       " 'iraq',\n",
       " 'xmas',\n",
       " 'hearts',\n",
       " 'fav',\n",
       " 'dave',\n",
       " 'sura',\n",
       " 'album',\n",
       " 'wake',\n",
       " '4got',\n",
       " 'lengths',\n",
       " 'toothpaste',\n",
       " 'sensible',\n",
       " 'thangam',\n",
       " '22',\n",
       " 'govt',\n",
       " 'hunny',\n",
       " 'wellda',\n",
       " 'modl',\n",
       " 'violated',\n",
       " 'rub',\n",
       " 'gobi',\n",
       " 'apnt',\n",
       " 'faster',\n",
       " 'test',\n",
       " 'set',\n",
       " 'fights',\n",
       " 'tirunelvali',\n",
       " '151',\n",
       " 'dying',\n",
       " 'wheel',\n",
       " 'donyt',\n",
       " 'pics',\n",
       " 'credit',\n",
       " 'disturb',\n",
       " 'revealing',\n",
       " 'sony',\n",
       " 'thinked',\n",
       " 'names',\n",
       " 's',\n",
       " 'wan2',\n",
       " 'breakin',\n",
       " 'age16',\n",
       " 'idiot',\n",
       " 'desert',\n",
       " 'woould',\n",
       " 'bunkers',\n",
       " 'nevr',\n",
       " 'halloween',\n",
       " 'mates',\n",
       " 'inclusive',\n",
       " 'but',\n",
       " '78',\n",
       " 'seeing',\n",
       " 'perpetual',\n",
       " 'ie',\n",
       " 'wherevr',\n",
       " 'envelope',\n",
       " 'invention',\n",
       " 'well',\n",
       " '150p',\n",
       " 'application',\n",
       " 'defo',\n",
       " 'squid',\n",
       " 'gopalettan',\n",
       " 'busetop',\n",
       " 'child',\n",
       " 'details',\n",
       " '08715705022',\n",
       " 'nr31',\n",
       " '85555',\n",
       " 'digital',\n",
       " 'shola',\n",
       " 'psp',\n",
       " 'getzed',\n",
       " 'havn',\n",
       " 'try',\n",
       " 'getting',\n",
       " 'stagwood',\n",
       " 'talking',\n",
       " 'praying',\n",
       " 'whore',\n",
       " 'happily',\n",
       " 'teju',\n",
       " 'lifebook',\n",
       " 'eightish',\n",
       " 'wildest',\n",
       " 'badass',\n",
       " 'tues',\n",
       " 'china',\n",
       " 'aspects',\n",
       " 'stripes',\n",
       " 'lotsly',\n",
       " '08717509990',\n",
       " 'crash',\n",
       " 'pushbutton',\n",
       " '85233',\n",
       " 'spun',\n",
       " 'payback',\n",
       " 'cell',\n",
       " 'dom',\n",
       " 'prizes',\n",
       " 'kavalan',\n",
       " 'slide',\n",
       " 'jerry',\n",
       " '255',\n",
       " 'curry',\n",
       " 'pizza',\n",
       " 'renewal',\n",
       " 'shop',\n",
       " 'tonexs',\n",
       " 'support',\n",
       " 'betta',\n",
       " 'slacking',\n",
       " 'gail',\n",
       " 'surrender',\n",
       " 'boss',\n",
       " 'itxt',\n",
       " 'minuts',\n",
       " 'thanku',\n",
       " 'surf',\n",
       " 'october',\n",
       " 'teachers',\n",
       " 'bruce',\n",
       " 'bone',\n",
       " 'further',\n",
       " 'stop',\n",
       " 'same',\n",
       " 'finding',\n",
       " 'rush',\n",
       " '250k',\n",
       " 'smoke',\n",
       " 'thesis',\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b5d62c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_text = {'secret': [2,1,1],\n",
    "                       'prize': [2,0,1],\n",
    "                       'claim': [1,0,1],\n",
    "                       'now': [1,0,1],\n",
    "                       'coming': [0,1,0],\n",
    "                       'to': [0,1,0],\n",
    "                       'my': [0,1,0],\n",
    "                       'party': [0,1,0],\n",
    "                       'winner': [0,0,1]\n",
    "                      }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb21707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'secret': [2, 1, 1],\n",
       " 'prize': [2, 0, 1],\n",
       " 'claim': [1, 0, 1],\n",
       " 'now': [1, 0, 1],\n",
       " 'coming': [0, 1, 0],\n",
       " 'to': [0, 1, 0],\n",
       " 'my': [0, 1, 0],\n",
       " 'party': [0, 1, 0],\n",
       " 'winner': [0, 0, 1]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "694802fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secret</th>\n",
       "      <th>prize</th>\n",
       "      <th>claim</th>\n",
       "      <th>now</th>\n",
       "      <th>coming</th>\n",
       "      <th>to</th>\n",
       "      <th>my</th>\n",
       "      <th>party</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secret  prize  claim  now  coming  to  my  party  winner\n",
       "0       2      2      1    1       0   0   0      0       0\n",
       "1       1      0      0    0       1   1   1      1       0\n",
       "2       1      1      1    1       0   0   0      0       1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_text)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d76a2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTo create the dictionary we need for our training set\\n\\nWe start by initializing a dictionary named word_counts_per_text, where each key is a\\nunique word (a string) from the vocabulary, and each value is a list of the length of the training set, \\nwhere each element in that list is a 0.\\nThe code [0] * 5 outputs [0, 0, 0, 0, 0]. So the code [0] * len(training_set['text']) outputs a list of the \\nlength of training_set['text'].\\nWe loop over training_set['text'] using the enumerate() function to get both the index and the text message (index and text).\\nUsing a nested loop, we loop over text (where text is a list of strings, where each string represents a word in a message).\\nWe increment word_counts_per_text[word][index] by 1.\\n\\nword_counts_per_text = {unique_word: [0] * len(training_set['text']) for unique_word in vocabulary}\\n\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "To create the dictionary we need for our training set\n",
    "\n",
    "We start by initializing a dictionary named word_counts_per_text, where each key is a\n",
    "unique word (a string) from the vocabulary, and each value is a list of the length of the training set, \n",
    "where each element in that list is a 0.\n",
    "The code [0] * 5 outputs [0, 0, 0, 0, 0]. So the code [0] * len(training_set['text']) outputs a list of the \n",
    "length of training_set['text'].\n",
    "We loop over training_set['text'] using the enumerate() function to get both the index and the text message (index and text).\n",
    "Using a nested loop, we loop over text (where text is a list of strings, where each string represents a word in a message).\n",
    "We increment word_counts_per_text[word][index] by 1.\n",
    "\n",
    "word_counts_per_text = {unique_word: [0] * len(training_set['text']) for unique_word in vocabulary}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "489e3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['text']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['text']):\n",
    "   for word in sms:\n",
    "      word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e7e6850",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>88800</th>\n",
       "      <th>drug</th>\n",
       "      <th>beendropping</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>rings</th>\n",
       "      <th>mids</th>\n",
       "      <th>downon</th>\n",
       "      <th>greatness</th>\n",
       "      <th>pieces</th>\n",
       "      <th>3230</th>\n",
       "      <th>...</th>\n",
       "      <th>award</th>\n",
       "      <th>cars</th>\n",
       "      <th>late</th>\n",
       "      <th>w1a</th>\n",
       "      <th>watts</th>\n",
       "      <th>witot</th>\n",
       "      <th>vague</th>\n",
       "      <th>sw7</th>\n",
       "      <th>apes</th>\n",
       "      <th>gam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7802 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   88800  drug  beendropping  epsilon  rings  mids  downon  greatness  pieces  \\\n",
       "0      0     0             0        0      0     0       0          0       0   \n",
       "1      0     0             0        0      0     0       0          0       0   \n",
       "2      0     0             0        0      0     0       0          0       0   \n",
       "3      0     0             0        0      0     0       0          0       0   \n",
       "4      0     0             0        0      0     0       0          0       0   \n",
       "\n",
       "   3230  ...  award  cars  late  w1a  watts  witot  vague  sw7  apes  gam  \n",
       "0     0  ...      0     0     0    0      0      0      0    0     0    0  \n",
       "1     0  ...      0     0     0    0      0      0      0    0     0    0  \n",
       "2     0  ...      0     0     0    0      0      0      0    0     0    0  \n",
       "3     0  ...      2     0     0    0      0      0      0    0     0    0  \n",
       "4     0  ...      0     0     0    0      0      0      0    0     0    0  \n",
       "\n",
       "[5 rows x 7802 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68c4913f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "      <th>88800</th>\n",
       "      <th>drug</th>\n",
       "      <th>beendropping</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>rings</th>\n",
       "      <th>mids</th>\n",
       "      <th>downon</th>\n",
       "      <th>greatness</th>\n",
       "      <th>...</th>\n",
       "      <th>award</th>\n",
       "      <th>cars</th>\n",
       "      <th>late</th>\n",
       "      <th>w1a</th>\n",
       "      <th>watts</th>\n",
       "      <th>witot</th>\n",
       "      <th>vague</th>\n",
       "      <th>sw7</th>\n",
       "      <th>apes</th>\n",
       "      <th>gam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[looks, like, u, wil, b, getting, a, headstart...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, noe, la, u, wana, pei, bf, oso, rite, k, l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[2mro, i, am, not, coming, to, gym, machan, go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>[todays, vodafone, numbers, ending, with, 4882...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[hi, hope, ur, day, good, back, from, walk, ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7804 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               text  88800  drug  \\\n",
       "0   ham  [looks, like, u, wil, b, getting, a, headstart...      0     0   \n",
       "1   ham  [i, noe, la, u, wana, pei, bf, oso, rite, k, l...      0     0   \n",
       "2   ham  [2mro, i, am, not, coming, to, gym, machan, go...      0     0   \n",
       "3  spam  [todays, vodafone, numbers, ending, with, 4882...      0     0   \n",
       "4   ham  [hi, hope, ur, day, good, back, from, walk, ta...      0     0   \n",
       "\n",
       "   beendropping  epsilon  rings  mids  downon  greatness  ...  award  cars  \\\n",
       "0             0        0      0     0       0          0  ...      0     0   \n",
       "1             0        0      0     0       0          0  ...      0     0   \n",
       "2             0        0      0     0       0          0  ...      0     0   \n",
       "3             0        0      0     0       0          0  ...      2     0   \n",
       "4             0        0      0     0       0          0  ...      0     0   \n",
       "\n",
       "   late  w1a  watts  witot  vague  sw7  apes  gam  \n",
       "0     0    0      0      0      0    0     0    0  \n",
       "1     0    0      0      0      0    0     0    0  \n",
       "2     0    0      0      0      0    0     0    0  \n",
       "3     0    0      0      0      0    0     0    0  \n",
       "4     0    0      0      0      0    0     0    0  \n",
       "\n",
       "[5 rows x 7804 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.columns.values[0] = \"Label\"\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49e457b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "      <th>88800</th>\n",
       "      <th>drug</th>\n",
       "      <th>beendropping</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>rings</th>\n",
       "      <th>mids</th>\n",
       "      <th>downon</th>\n",
       "      <th>greatness</th>\n",
       "      <th>...</th>\n",
       "      <th>award</th>\n",
       "      <th>cars</th>\n",
       "      <th>late</th>\n",
       "      <th>w1a</th>\n",
       "      <th>watts</th>\n",
       "      <th>witot</th>\n",
       "      <th>vague</th>\n",
       "      <th>sw7</th>\n",
       "      <th>apes</th>\n",
       "      <th>gam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>[todays, vodafone, numbers, ending, with, 4882...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>[we, tried, to, contact, you, re, our, offer, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, why, haven, t, you, replied, to, my,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>spam</td>\n",
       "      <td>[loans, for, any, purpose, even, if, you, have...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>spam</td>\n",
       "      <td>[would, you, like, to, see, my, xxx, pics, the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7804 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                               text  88800  drug  \\\n",
       "3   spam  [todays, vodafone, numbers, ending, with, 4882...      0     0   \n",
       "6   spam  [we, tried, to, contact, you, re, our, offer, ...      0     0   \n",
       "16  spam  [freemsg, why, haven, t, you, replied, to, my,...      0     0   \n",
       "25  spam  [loans, for, any, purpose, even, if, you, have...      0     0   \n",
       "47  spam  [would, you, like, to, see, my, xxx, pics, the...      0     0   \n",
       "\n",
       "    beendropping  epsilon  rings  mids  downon  greatness  ...  award  cars  \\\n",
       "3              0        0      0     0       0          0  ...      2     0   \n",
       "6              0        0      0     0       0          0  ...      0     0   \n",
       "16             0        0      0     0       0          0  ...      0     0   \n",
       "25             0        0      0     0       0          0  ...      0     0   \n",
       "47             0        0      0     0       0          0  ...      0     0   \n",
       "\n",
       "    late  w1a  watts  witot  vague  sw7  apes  gam  \n",
       "3      0    0      0      0      0    0     0    0  \n",
       "6      0    0      0      0      0    0     0    0  \n",
       "16     0    0      0      0      0    0     0    0  \n",
       "25     0    0      0      0      0    0     0    0  \n",
       "47     0    0      0      0      0    0     0    0  \n",
       "\n",
       "[5 rows x 7804 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolating spam and ham messages first\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "spam_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ecfc3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "04121715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages['text'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e4419ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bfe1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_Ham\n",
    "n_words_per_ham_message = ham_messages['text'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166c41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57367"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fb129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb5c85",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'baller'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'baller'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate parameters\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m vocabulary:\n\u001b[1;32m----> 3\u001b[0m    n_word_given_spam \u001b[38;5;241m=\u001b[39m \u001b[43mspam_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;66;03m# spam_messages already defined\u001b[39;00m\n\u001b[0;32m      4\u001b[0m    p_word_given_spam \u001b[38;5;241m=\u001b[39m (n_word_given_spam \u001b[38;5;241m+\u001b[39m alpha) \u001b[38;5;241m/\u001b[39m (n_spam \u001b[38;5;241m+\u001b[39m alpha\u001b[38;5;241m*\u001b[39mn_vocabulary)\n\u001b[0;32m      5\u001b[0m    parameters_spam[word] \u001b[38;5;241m=\u001b[39m p_word_given_spam\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'baller'"
     ]
    }
   ],
   "source": [
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "   n_word_given_spam = spam_messages[word].sum() # spam_messages already defined\n",
    "   p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "   parameters_spam[word] = p_word_given_spam\n",
    "   n_word_given_ham = ham_messages[word].sum() # ham_messages already defined\n",
    "   p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "   parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6414574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
